{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 30,
            "id": "2ce782e8",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import re\n",
                "import ast\n",
                "import umap\n",
                "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.metrics import roc_auc_score, log_loss, confusion_matrix, classification_report\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.calibration import CalibratedClassifierCV\n",
                "from sklearn.decomposition import TruncatedSVD\n",
                "\n",
                "import warnings\n",
                "\n",
                "warnings.filterwarnings(\"ignore\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "id": "804da16c",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 13536 entries, 0 to 13535\n",
                        "Data columns (total 17 columns):\n",
                        " #   Column                   Non-Null Count  Dtype \n",
                        "---  ------                   --------------  ----- \n",
                        " 0   ID                       13536 non-null  object\n",
                        " 1   farmer_name              13536 non-null  object\n",
                        " 2   training_day             13536 non-null  object\n",
                        " 3   gender                   13536 non-null  object\n",
                        " 4   registration             13536 non-null  object\n",
                        " 5   age                      13536 non-null  object\n",
                        " 6   group_name               13536 non-null  object\n",
                        " 7   belong_to_cooperative    13536 non-null  int64 \n",
                        " 8   county                   13536 non-null  object\n",
                        " 9   subcounty                13536 non-null  object\n",
                        " 10  ward                     13536 non-null  object\n",
                        " 11  adopted_within_07_days   13536 non-null  int64 \n",
                        " 12  adopted_within_90_days   13536 non-null  int64 \n",
                        " 13  adopted_within_120_days  13536 non-null  int64 \n",
                        " 14  has_topic_trained_on     13536 non-null  int64 \n",
                        " 15  trainer                  13536 non-null  object\n",
                        " 16  topics_list              13536 non-null  object\n",
                        "dtypes: int64(5), object(12)\n",
                        "memory usage: 1.8+ MB\n",
                        "None\n",
                        "          ID  farmer_name training_day  gender registration       age  \\\n",
                        "0  ID_CENCC8  FAR_eqbhscj   2024-01-03  Female       Manual  Above 35   \n",
                        "1  ID_YTO0FF  FAR_qlwtyik   2024-01-03  Female       Manual  Above 35   \n",
                        "2  ID_1476PE  FAR_somfzxp   2024-01-03  Female       Manual  Above 35   \n",
                        "3  ID_MLKLIR  FAR_ongcqyd   2024-01-03  Female       Manual  Above 35   \n",
                        "4  ID_V5ZVTA  FAR_ztsbhhm   2024-01-03  Female         Ussd  Below 35   \n",
                        "\n",
                        "    group_name  belong_to_cooperative      county    subcounty          ward  \\\n",
                        "0  GRP_yvpakgc                      0  CNT_lpotuu  SUB_lpotuuf  WRD_lpotuufh   \n",
                        "1  GRP_zemrbsy                      1  CNT_fhdsoy  SUB_mdyljqn  WRD_atkhhvon   \n",
                        "2  GRP_zmblxsw                      0  CNT_fhdsoy  SUB_mdyljqn  WRD_atkhhvon   \n",
                        "3  GRP_psdrfni                      0  CNT_fhdsoy  SUB_mdyljqn  WRD_atkhhvon   \n",
                        "4  GRP_yvpakgc                      0  CNT_lpotuu  SUB_lpotuuf  WRD_lpotuufh   \n",
                        "\n",
                        "   adopted_within_07_days  adopted_within_90_days  adopted_within_120_days  \\\n",
                        "0                       0                       0                        0   \n",
                        "1                       0                       0                        0   \n",
                        "2                       0                       0                        0   \n",
                        "3                       0                       0                        0   \n",
                        "4                       0                       0                        0   \n",
                        "\n",
                        "   has_topic_trained_on       trainer  \\\n",
                        "0                     0  TRA_szrwyfzz   \n",
                        "1                     1  TRA_rkvyofbh   \n",
                        "2                     1  TRA_rkvyofbh   \n",
                        "3                     1  TRA_rkvyofbh   \n",
                        "4                     0  TRA_szrwyfzz   \n",
                        "\n",
                        "                                         topics_list  \n",
                        "0                 [['Ndume App', 'Poultry Feeding']]  \n",
                        "1         [['Poultry Housing'], ['Poultry Housing']]  \n",
                        "2  [['Asili Fertilizer (Organic)', 'Biosecurity I...  \n",
                        "3  [['Poultry Products'], ['Record Keeping In Dai...  \n",
                        "4                 [['Ndume App', 'Poultry Feeding']]  \n"
                    ]
                }
            ],
            "source": [
                "df = pd.read_csv(\"Original Data/Train.csv\")\n",
                "print(df.info())\n",
                "df[\"trainer\"] = df[\"trainer\"].apply(lambda x: ast.literal_eval(x)[0])\n",
                "print(df.head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "id": "e08affae",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 44882 entries, 0 to 44881\n",
                        "Data columns (total 17 columns):\n",
                        " #   Column                   Non-Null Count  Dtype \n",
                        "---  ------                   --------------  ----- \n",
                        " 0   ID                       44882 non-null  object\n",
                        " 1   farmer_name              44882 non-null  object\n",
                        " 2   training_day             44882 non-null  object\n",
                        " 3   gender                   44882 non-null  object\n",
                        " 4   registration             44882 non-null  object\n",
                        " 5   age                      44882 non-null  object\n",
                        " 6   group_name               44882 non-null  object\n",
                        " 7   belong_to_cooperative    44882 non-null  int64 \n",
                        " 8   county                   44882 non-null  object\n",
                        " 9   subcounty                44882 non-null  object\n",
                        " 10  ward                     44882 non-null  object\n",
                        " 11  adopted_within_07_days   44882 non-null  int64 \n",
                        " 12  adopted_within_90_days   44882 non-null  int64 \n",
                        " 13  adopted_within_120_days  44882 non-null  int64 \n",
                        " 14  has_topic_trained_on     44882 non-null  int64 \n",
                        " 15  trainer                  44882 non-null  object\n",
                        " 16  topics_list              44882 non-null  object\n",
                        "dtypes: int64(5), object(12)\n",
                        "memory usage: 5.8+ MB\n",
                        "None\n",
                        "\n",
                        "Original columns: ['ID', 'farmer_name', 'training_day', 'gender', 'registration', 'age', 'group_name', 'belong_to_cooperative', 'county', 'subcounty', 'ward', 'adopted_within_07_days', 'adopted_within_90_days', 'adopted_within_120_days', 'has_topic_trained_on', 'trainer', 'topics_list']\n",
                        "          ID  farmer_name training_day  gender registration       age  \\\n",
                        "0  ID_70GP6F  FAR_leopgvh   2024-01-03  Female       Manual  Above 35   \n",
                        "1  ID_IWQOWJ  FAR_vdcjfxm   2024-01-03  Female         Ussd  Above 35   \n",
                        "2  ID_Z3ES85  FAR_hfkybdg   2024-01-03  Female       Manual  Above 35   \n",
                        "3  ID_JNZM6R  FAR_hfkybdg   2024-01-03  Female       Manual  Above 35   \n",
                        "4  ID_BNJ1GU  FAR_hfkybdg   2024-01-03  Female       Manual  Above 35   \n",
                        "\n",
                        "    group_name  belong_to_cooperative      county    subcounty          ward  \\\n",
                        "0  GRP_yvpakgc                      0  CNT_lpotuu  SUB_lpotuuf  WRD_lpotuufh   \n",
                        "1  GRP_yvpakgc                      0  CNT_lpotuu  SUB_lpotuuf  WRD_lpotuufh   \n",
                        "2  GRP_zmblxsw                      0  CNT_fhdsoy  SUB_mdyljqn  WRD_atkhhvon   \n",
                        "3  GRP_psdrfni                      0  CNT_fhdsoy  SUB_mdyljqn  WRD_atkhhvon   \n",
                        "4  GRP_psdrfni                      1  CNT_fhdsoy  SUB_mdyljqn  WRD_atkhhvon   \n",
                        "\n",
                        "   adopted_within_07_days  adopted_within_90_days  adopted_within_120_days  \\\n",
                        "0                       0                       0                        0   \n",
                        "1                       0                       0                        0   \n",
                        "2                       0                       0                        0   \n",
                        "3                       0                       0                        0   \n",
                        "4                       0                       0                        0   \n",
                        "\n",
                        "   has_topic_trained_on       trainer  \\\n",
                        "0                     0  TRA_szrwyfzz   \n",
                        "1                     0  TRA_szrwyfzz   \n",
                        "2                     1  TRA_rkvyofbh   \n",
                        "3                     1  TRA_rkvyofbh   \n",
                        "4                     1  TRA_rkvyofbh   \n",
                        "\n",
                        "                                         topics_list  \n",
                        "0                   ['Ndume App', 'Poultry Feeding']  \n",
                        "1                   ['Ndume App', 'Poultry Feeding']  \n",
                        "2  ['Asili Fertilizer (Organic)', 'Biosecurity In...  \n",
                        "3                               ['Poultry Products']  \n",
                        "4                        ['Record Keeping In Dairy']  \n"
                    ]
                }
            ],
            "source": [
                "prior_df = pd.read_csv(\"Original Data/Prior.csv\")\n",
                "print(prior_df.info())\n",
                "print(f\"\\nOriginal columns: {prior_df.columns.tolist()}\")\n",
                "print(prior_df.head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "id": "50b4c373",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 58418 entries, 0 to 58417\n",
                        "Data columns (total 17 columns):\n",
                        " #   Column                   Non-Null Count  Dtype \n",
                        "---  ------                   --------------  ----- \n",
                        " 0   ID                       58418 non-null  object\n",
                        " 1   farmer_name              58418 non-null  object\n",
                        " 2   training_day             58418 non-null  object\n",
                        " 3   gender                   58418 non-null  object\n",
                        " 4   registration             58418 non-null  object\n",
                        " 5   age                      58418 non-null  object\n",
                        " 6   group_name               58418 non-null  object\n",
                        " 7   belong_to_cooperative    58418 non-null  int64 \n",
                        " 8   county                   58418 non-null  object\n",
                        " 9   subcounty                58418 non-null  object\n",
                        " 10  ward                     58418 non-null  object\n",
                        " 11  adopted_within_07_days   58418 non-null  int64 \n",
                        " 12  adopted_within_90_days   58418 non-null  int64 \n",
                        " 13  adopted_within_120_days  58418 non-null  int64 \n",
                        " 14  has_topic_trained_on     58418 non-null  int64 \n",
                        " 15  trainer                  58418 non-null  object\n",
                        " 16  topics_list              58418 non-null  object\n",
                        "dtypes: int64(5), object(12)\n",
                        "memory usage: 7.6+ MB\n",
                        "None\n"
                    ]
                }
            ],
            "source": [
                "combined_df = pd.concat([df, prior_df], ignore_index=True)\n",
                "df = combined_df.copy()\n",
                "print(df.info())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "id": "b4880f76",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Total features: 163\n",
                        "  - Topic features: 149\n",
                        "  - Other features: 14\n",
                        "Categorical columns encoded: 8\n",
                        "Final dataframe shape: (58418, 166)\n",
                        "   gender  registration  age  group_name  belong_to_cooperative  county  \\\n",
                        "0       0             0    0         942                      0       3   \n",
                        "1       0             0    0         956                      1       0   \n",
                        "2       0             0    0         972                      0       0   \n",
                        "3       0             0    0         600                      0       0   \n",
                        "4       0             1    1         942                      0       3   \n",
                        "\n",
                        "   subcounty  ward  has_topic_trained_on  trainer  ...  \\\n",
                        "0         16    40                     0        6  ...   \n",
                        "1         17     1                     1        4  ...   \n",
                        "2         17     1                     1        4  ...   \n",
                        "3         17     1                     1        4  ...   \n",
                        "4         16    40                     0        6  ...   \n",
                        "\n",
                        "   topic_weed management in maize and beans  \\\n",
                        "0                                         0   \n",
                        "1                                         0   \n",
                        "2                                         1   \n",
                        "3                                         0   \n",
                        "4                                         0   \n",
                        "\n",
                        "   topic_why you should vaccinate your animals  topic_yara maziwa pro  \\\n",
                        "0                                            0                      0   \n",
                        "1                                            0                      0   \n",
                        "2                                            0                      0   \n",
                        "3                                            0                      0   \n",
                        "4                                            0                      0   \n",
                        "\n",
                        "   training_year  training_month  training_day_number  training_dayofweek  \\\n",
                        "0           2024               3                    1                   4   \n",
                        "1           2024               3                    1                   4   \n",
                        "2           2024               3                    1                   4   \n",
                        "3           2024               3                    1                   4   \n",
                        "4           2024               3                    1                   4   \n",
                        "\n",
                        "   adopted_within_07_days  adopted_within_90_days  adopted_within_120_days  \n",
                        "0                       0                       0                        0  \n",
                        "1                       0                       0                        0  \n",
                        "2                       0                       0                        0  \n",
                        "3                       0                       0                        0  \n",
                        "4                       0                       0                        0  \n",
                        "\n",
                        "[5 rows x 166 columns]\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
                "import pandas as pd\n",
                "import ast\n",
                "\n",
                "def preprocess_data(df):\n",
                "    def clean_and_flat_topics(topic_str):\n",
                "        if not isinstance(topic_str, str) or pd.isna(topic_str):\n",
                "            return []\n",
                "        \n",
                "        try:\n",
                "            parsed = ast.literal_eval(topic_str)\n",
                "        except (ValueError, SyntaxError):\n",
                "            return []\n",
                "\n",
                "        flat_topics = []\n",
                "        def flatten(item):\n",
                "            if isinstance(item, list):\n",
                "                for sub in item:\n",
                "                    flatten(sub)\n",
                "            elif isinstance(item, str):\n",
                "                flat_topics.append(item)\n",
                "        flatten(parsed)\n",
                "        cleaned = sorted(list(set([t.lower().strip() for t in flat_topics if t])))\n",
                "        return cleaned\n",
                "\n",
                "    # --- Topics ---\n",
                "    df['clean_topics'] = df['topics_list'].apply(clean_and_flat_topics)\n",
                "    mlb = MultiLabelBinarizer()\n",
                "    topics_encoded = mlb.fit_transform(df['clean_topics'])\n",
                "    topic_columns = [f'topic_{t}' for t in mlb.classes_]\n",
                "    topics_df = pd.DataFrame(topics_encoded, columns=topic_columns, index=df.index)\n",
                "    df = pd.concat([df, topics_df], axis=1)\n",
                "\n",
                "    # --- Date features ---\n",
                "    df['training_day'] = pd.to_datetime(df['training_day'], dayfirst=True)\n",
                "    df['training_year'] = df['training_day'].dt.year\n",
                "    df['training_month'] = df['training_day'].dt.month\n",
                "    df['training_day_number'] = df['training_day'].dt.day\n",
                "    df['training_dayofweek'] = df['training_day'].dt.dayofweek\n",
                "\n",
                "    # --- Targets & Features ---\n",
                "    TARGETS = [    \n",
                "        'adopted_within_07_days',\n",
                "        'adopted_within_90_days',\n",
                "        'adopted_within_120_days',\n",
                "    ]\n",
                "\n",
                "    exclude_cols = ['ID', 'farmer_name', 'training_day', 'topics_list', 'clean_topics'] + TARGETS\n",
                "    FEATURES = [c for c in df.columns if c not in exclude_cols]\n",
                "\n",
                "    # --- Categorical encoding ---\n",
                "    categorical_cols = [c for c in df.select_dtypes(include=[\"object\"]).columns if c in FEATURES]\n",
                "    label_encoders = {}\n",
                "    for col in categorical_cols:\n",
                "        le = LabelEncoder()\n",
                "        df[col] = df[col].astype(str).fillna(\"NA\")\n",
                "        df[col] = le.fit_transform(df[col])\n",
                "        label_encoders[col] = le\n",
                "\n",
                "    # --- Keep only features + targets ---\n",
                "    df = df[FEATURES + TARGETS].copy()\n",
                "\n",
                "    print(f\"Total features: {len(FEATURES)}\")\n",
                "    print(f\"  - Topic features: {len([f for f in FEATURES if f.startswith('topic_')])}\")\n",
                "    print(f\"  - Other features: {len([f for f in FEATURES if not f.startswith('topic_')])}\")\n",
                "    print(f\"Categorical columns encoded: {len(categorical_cols)}\")\n",
                "    print(f\"Final dataframe shape: {df.shape}\")\n",
                "\n",
                "    # --- RETURN EVERYTHING NEEDED OUTSIDE ---\n",
                "    return df, FEATURES, topic_columns, mlb, label_encoders, TARGETS\n",
                "\n",
                "# --- Usage ---\n",
                "df, FEATURES, topic_columns, mlb, label_encoders, TARGETS = preprocess_data(combined_df)\n",
                "print(df.head())\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b409d5d2",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[nltk_data] Downloading package wordnet to /home/nzioka/nltk_data...\n",
                        "[nltk_data]   Package wordnet is already up-to-date!\n",
                        "[nltk_data] Downloading package omw-1.4 to /home/nzioka/nltk_data...\n",
                        "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Converting topic features to text with preprocessing and lemmatization...\n",
                        "\n",
                        "Sample topic texts (after cleaning and lemmatization):\n",
                        "  1. ndume app poultry feed\n",
                        "  2. poultry house\n",
                        "  3. asili fertilizer organic biosecurity in poultry farm calf feed dairy health management dairy nutriti...\n",
                        "  4. poultry house poultry product record keep in dairy\n",
                        "  5. ndume app poultry feed\n",
                        "\n",
                        "Topic text statistics:\n",
                        "  Words per farmer: min=2, max=161, mean=6.8\n",
                        "  Farmers with no topics: 0\n",
                        "\n",
                        "======================================================================\n",
                        "Creating engineered features from topics...\n",
                        "======================================================================\n",
                        "\n",
                        "Engineered features created:\n",
                        "  Livestock topics found: 86\n",
                        "  Crop topics found: 21\n",
                        "  Business topics found: 43\n",
                        "  Health topics found: 40\n",
                        "  Feed topics found: 27\n",
                        "\n",
                        "Total engineered features: 26\n",
                        "\n",
                        "Sample engineered features:\n",
                        "   topic_count  topic_diversity  livestock_count  crop_count  business_count  \\\n",
                        "0            2         0.013423                1           0               0   \n",
                        "1            1         0.006711                1           0               0   \n",
                        "2           29         0.194631               21           6               7   \n",
                        "3            3         0.020134                3           0               1   \n",
                        "4            2         0.013423                1           0               0   \n",
                        "\n",
                        "   health_count  feed_count  livestock_pct  crop_pct  business_pct  ...  \\\n",
                        "0             0           1       0.500000  0.000000      0.000000  ...   \n",
                        "1             0           0       1.000000  0.000000      0.000000  ...   \n",
                        "2            10          10       0.724138  0.206897      0.241379  ...   \n",
                        "3             0           0       1.000000  0.000000      0.333333  ...   \n",
                        "4             0           1       0.500000  0.000000      0.000000  ...   \n",
                        "\n",
                        "   has_business  has_health  has_feed  has_livestock_and_business  \\\n",
                        "0             0           0         1                           0   \n",
                        "1             0           0         0                           0   \n",
                        "2             1           1         1                           1   \n",
                        "3             1           0         0                           1   \n",
                        "4             0           0         1                           0   \n",
                        "\n",
                        "   has_livestock_and_health  has_crop_and_business  is_diversified  \\\n",
                        "0                         0                      0               0   \n",
                        "1                         0                      0               0   \n",
                        "2                         1                      1               1   \n",
                        "3                         0                      0               0   \n",
                        "4                         0                      0               0   \n",
                        "\n",
                        "   num_domains_covered  has_comprehensive_training  avg_topics_per_domain  \n",
                        "0                    2                           0                    1.0  \n",
                        "1                    1                           0                    1.0  \n",
                        "2                    5                           1                    5.8  \n",
                        "3                    2                           0                    1.5  \n",
                        "4                    2                           0                    1.0  \n",
                        "\n",
                        "[5 rows x 26 columns]\n",
                        "\n",
                        "Engineered feature statistics:\n",
                        "        topic_count  topic_diversity  livestock_count    crop_count  \\\n",
                        "count  58418.000000     58418.000000     58418.000000  58418.000000   \n",
                        "mean       1.616454         0.010849         1.102212      0.227293   \n",
                        "std        1.958224         0.013142         1.579287      0.522136   \n",
                        "min        1.000000         0.006711         0.000000      0.000000   \n",
                        "25%        1.000000         0.006711         0.000000      0.000000   \n",
                        "50%        1.000000         0.006711         1.000000      0.000000   \n",
                        "75%        1.000000         0.006711         1.000000      0.000000   \n",
                        "max       34.000000         0.228188        25.000000      8.000000   \n",
                        "\n",
                        "       business_count  health_count    feed_count  livestock_pct  \\\n",
                        "count    58418.000000  58418.000000  58418.000000   58418.000000   \n",
                        "mean         0.592266      0.492896      0.303554       0.650061   \n",
                        "std          0.848679      0.923134      0.775700       0.448719   \n",
                        "min          0.000000      0.000000      0.000000       0.000000   \n",
                        "25%          0.000000      0.000000      0.000000       0.000000   \n",
                        "50%          0.000000      0.000000      0.000000       1.000000   \n",
                        "75%          1.000000      1.000000      0.000000       1.000000   \n",
                        "max         10.000000     14.000000     12.000000       1.000000   \n",
                        "\n",
                        "           crop_pct  business_pct  ...  has_business    has_health  \\\n",
                        "count  58418.000000  58418.000000  ...  58418.000000  58418.000000   \n",
                        "mean       0.149564      0.382433  ...      0.455972      0.352237   \n",
                        "std        0.336715      0.455857  ...      0.498062      0.477672   \n",
                        "min        0.000000      0.000000  ...      0.000000      0.000000   \n",
                        "25%        0.000000      0.000000  ...      0.000000      0.000000   \n",
                        "50%        0.000000      0.000000  ...      0.000000      0.000000   \n",
                        "75%        0.000000      1.000000  ...      1.000000      1.000000   \n",
                        "max        1.000000      1.000000  ...      1.000000      1.000000   \n",
                        "\n",
                        "           has_feed  has_livestock_and_business  has_livestock_and_health  \\\n",
                        "count  58418.000000                58418.000000              58418.000000   \n",
                        "mean       0.218049                    0.389349                  0.287411   \n",
                        "std        0.412925                    0.487607                  0.452559   \n",
                        "min        0.000000                    0.000000                  0.000000   \n",
                        "25%        0.000000                    0.000000                  0.000000   \n",
                        "50%        0.000000                    0.000000                  0.000000   \n",
                        "75%        0.000000                    1.000000                  1.000000   \n",
                        "max        1.000000                    1.000000                  1.000000   \n",
                        "\n",
                        "       has_crop_and_business  is_diversified  num_domains_covered  \\\n",
                        "count           58418.000000    58418.000000         58418.000000   \n",
                        "mean                0.100089        0.087251             1.921377   \n",
                        "std                 0.300121        0.282204             1.168572   \n",
                        "min                 0.000000        0.000000             0.000000   \n",
                        "25%                 0.000000        0.000000             1.000000   \n",
                        "50%                 0.000000        0.000000             2.000000   \n",
                        "75%                 0.000000        0.000000             3.000000   \n",
                        "max                 1.000000        1.000000             5.000000   \n",
                        "\n",
                        "       has_comprehensive_training  avg_topics_per_domain  \n",
                        "count                58418.000000           58418.000000  \n",
                        "mean                     0.240474               0.789378  \n",
                        "std                      0.427375               0.470658  \n",
                        "min                      0.000000               0.333333  \n",
                        "25%                      0.000000               0.500000  \n",
                        "50%                      0.000000               0.666667  \n",
                        "75%                      0.000000               1.000000  \n",
                        "max                      1.000000               6.800000  \n",
                        "\n",
                        "[8 rows x 26 columns]\n",
                        "\n",
                        "Total base features (original + engineered): 40\n",
                        "  - Original features: 14\n",
                        "  - Engineered features: 26\n",
                        "\n",
                        "====================================================================== Training for 7 Days ======================================================================\n",
                        "\n",
                        "--- TF-IDF max_features=30 (NO SVD compression) ---\n",
                        "  TF-IDF shape: (46734, 30)\n",
                        "  Sparsity: 88.74%\n",
                        "  Top features: ['app', 'benefit', 'biodeal', 'chicken', 'cow', 'dairy', 'disease', 'farm', 'fee', 'feed']\n",
                        "  Final feature count: 70 (base: 40, tfidf: 30)\n",
                        "  Training model... AUC=0.9715, LogLoss=0.0426\n",
                        "\n",
                        "--- TF-IDF max_features=50 (NO SVD compression) ---\n",
                        "  TF-IDF shape: (46734, 50)\n",
                        "  Sparsity: 91.59%\n",
                        "  Top features: ['animal', 'app', 'benefit', 'benefit ndume', 'biodeal', 'biosecurity', 'biosecurity poultry', 'breed', 'calf', 'chicken']\n",
                        "  Final feature count: 90 (base: 40, tfidf: 50)\n",
                        "  Training model... AUC=0.9712, LogLoss=0.0425\n",
                        "\n",
                        "--- TF-IDF max_features=75 (NO SVD compression) ---\n",
                        "  TF-IDF shape: (46734, 75)\n",
                        "  Sparsity: 93.38%\n",
                        "  Top features: ['aflatoxin', 'animal', 'app', 'bean', 'benefit', 'benefit ndume', 'biodeal', 'biosecurity', 'biosecurity poultry', 'breed']\n",
                        "  Final feature count: 115 (base: 40, tfidf: 75)\n",
                        "  Training model... AUC=0.9708, LogLoss=0.0424\n",
                        "\n",
                        "--- TF-IDF max_features=100 (NO SVD compression) ---\n",
                        "  TF-IDF shape: (46734, 100)\n",
                        "  Sparsity: 94.38%\n",
                        "  Top features: ['aflatoxin', 'aflatoxin dairy', 'animal', 'antimicrobial', 'antimicrobial resistance', 'app', 'bean', 'benefit', 'benefit ndume', 'biodeal']\n",
                        "  Final feature count: 140 (base: 40, tfidf: 100)\n",
                        "  Training model... AUC=0.9709, LogLoss=0.0423\n",
                        "\n",
                        "--- TF-IDF max_features=150 (NO SVD compression) ---\n",
                        "  TF-IDF shape: (46734, 150)\n",
                        "  Sparsity: 95.57%\n",
                        "  Top features: ['aflatoxin', 'aflatoxin dairy', 'animal', 'antimicrobial', 'antimicrobial resistance', 'app', 'asili', 'asili fertilizer', 'bean', 'benefit']\n",
                        "  Final feature count: 190 (base: 40, tfidf: 150)\n",
                        "  Training model... AUC=0.9692, LogLoss=0.0428\n",
                        "\n",
                        "--- TF-IDF max_features=200 (NO SVD compression) ---\n",
                        "  TF-IDF shape: (46734, 200)\n",
                        "  Sparsity: 96.35%\n",
                        "  Top features: ['aflatoxin', 'aflatoxin dairy', 'animal', 'animal health', 'antimicrobial', 'antimicrobial resistance', 'app', 'asili', 'asili fertilizer', 'bean']\n",
                        "  Final feature count: 240 (base: 40, tfidf: 200)\n",
                        "  Training model... AUC=0.9693, LogLoss=0.0427\n",
                        "\n",
                        "================================================================================\n",
                        "TF-IDF Configuration Comparison (NO SVD, WITH ENGINEERED FEATURES):\n",
                        " max_features  test_auc  test_logloss  n_tfidf_features\n",
                        "          100  0.970864      0.042348               100\n",
                        "           75  0.970814      0.042447                75\n",
                        "           50  0.971230      0.042489                50\n",
                        "           30  0.971540      0.042628                30\n",
                        "          200  0.969341      0.042680               200\n",
                        "          150  0.969203      0.042850               150\n",
                        "================================================================================\n",
                        "\n",
                        "✓ Selected Configuration:\n",
                        "  TF-IDF max_features: 100\n",
                        "  Actual TF-IDF features created: 100\n",
                        "  Test AUC: 0.9709\n",
                        "  Test Log Loss: 0.0423\n",
                        "\n",
                        "============================== Final Test Results ==============================\n",
                        "\n",
                        "Classification Report:\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.99      1.00      0.99     11521\n",
                        "           1       0.00      0.00      0.00       163\n",
                        "\n",
                        "    accuracy                           0.99     11684\n",
                        "   macro avg       0.49      0.50      0.50     11684\n",
                        "weighted avg       0.97      0.99      0.98     11684\n",
                        "\n",
                        "Confusion Matrix:\n",
                        "[[11521     0]\n",
                        " [  163     0]]\n",
                        "\n",
                        "Test AUC: 0.9709\n",
                        "Test Log Loss: 0.0423\n",
                        "\n",
                        "Top 15 most important ENGINEERED features:\n",
                        "  - feed_pct: 0.014342\n",
                        "  - health_pct: 0.013125\n",
                        "  - has_livestock_and_health: 0.010421\n",
                        "  - has_feed: 0.010221\n",
                        "  - num_domains_covered: 0.010106\n",
                        "  - feed_count: 0.009889\n",
                        "  - avg_topics_per_domain: 0.008732\n",
                        "  - livestock_pct: 0.007825\n",
                        "  - health_count: 0.007533\n",
                        "  - has_health: 0.007451\n",
                        "  - business_pct: 0.005977\n",
                        "  - livestock_count: 0.005596\n",
                        "  - max_domain_count: 0.004991\n",
                        "  - is_specialist: 0.004760\n",
                        "  - has_livestock: 0.004427\n",
                        "\n",
                        "Top 15 most important TF-IDF features:\n",
                        "  - health: 0.019678\n",
                        "  - tyari: 0.016248\n",
                        "  - mineral: 0.014846\n",
                        "  - mineral supplementation: 0.014703\n",
                        "  - supplementation: 0.014440\n",
                        "  - poultry health: 0.012427\n",
                        "  - poultry: 0.011779\n",
                        "  - management: 0.010746\n",
                        "  - animal: 0.010127\n",
                        "  - health management: 0.008798\n",
                        "  - management practice: 0.008651\n",
                        "  - dairy: 0.008613\n",
                        "  - practice: 0.007829\n",
                        "  - cow: 0.007100\n",
                        "  - feed: 0.005842\n",
                        "\n",
                        "Generating predicted probabilities on full dataset for chaining...\n",
                        "  Added 'adopted_within_07_days' predictions to feature set\n",
                        "  Prediction stats: min=0.0022, max=0.4503, mean=0.0145\n",
                        "\n",
                        "====================================================================== Training for 90 Days ======================================================================\n",
                        "\n",
                        "--- TF-IDF max_features=30 (NO SVD compression) ---\n",
                        "  TF-IDF shape: (46734, 30)\n",
                        "  Sparsity: 88.74%\n",
                        "  Top features: ['app', 'benefit', 'biodeal', 'chicken', 'cow', 'dairy', 'disease', 'farm', 'fee', 'feed']\n",
                        "  Final feature count: 71 (base: 41, tfidf: 30)\n",
                        "  Training model... AUC=0.9590, LogLoss=0.0773\n",
                        "\n",
                        "--- TF-IDF max_features=50 (NO SVD compression) ---\n",
                        "  TF-IDF shape: (46734, 50)\n",
                        "  Sparsity: 91.59%\n",
                        "  Top features: ['animal', 'app', 'benefit', 'benefit ndume', 'biodeal', 'biosecurity', 'biosecurity poultry', 'breed', 'calf', 'chicken']\n",
                        "  Final feature count: 91 (base: 41, tfidf: 50)\n",
                        "  Training model... AUC=0.9589, LogLoss=0.0772\n",
                        "\n",
                        "--- TF-IDF max_features=75 (NO SVD compression) ---\n",
                        "  TF-IDF shape: (46734, 75)\n",
                        "  Sparsity: 93.38%\n",
                        "  Top features: ['aflatoxin', 'animal', 'app', 'bean', 'benefit', 'benefit ndume', 'biodeal', 'biosecurity', 'biosecurity poultry', 'breed']\n",
                        "  Final feature count: 116 (base: 41, tfidf: 75)\n",
                        "  Training model... AUC=0.9579, LogLoss=0.0773\n",
                        "\n",
                        "--- TF-IDF max_features=100 (NO SVD compression) ---\n",
                        "  TF-IDF shape: (46734, 100)\n",
                        "  Sparsity: 94.38%\n",
                        "  Top features: ['aflatoxin', 'aflatoxin dairy', 'animal', 'antimicrobial', 'antimicrobial resistance', 'app', 'bean', 'benefit', 'benefit ndume', 'biodeal']\n",
                        "  Final feature count: 141 (base: 41, tfidf: 100)\n",
                        "  Training model... AUC=0.9581, LogLoss=0.0771\n",
                        "\n",
                        "--- TF-IDF max_features=150 (NO SVD compression) ---\n",
                        "  TF-IDF shape: (46734, 150)\n",
                        "  Sparsity: 95.58%\n",
                        "  Top features: ['aflatoxin', 'aflatoxin dairy', 'animal', 'antimicrobial', 'antimicrobial resistance', 'app', 'asili', 'asili fertilizer', 'bean', 'benefit']\n",
                        "  Final feature count: 191 (base: 41, tfidf: 150)\n",
                        "  Training model... AUC=0.9570, LogLoss=0.0773\n",
                        "\n",
                        "--- TF-IDF max_features=200 (NO SVD compression) ---\n",
                        "  TF-IDF shape: (46734, 200)\n",
                        "  Sparsity: 96.36%\n",
                        "  Top features: ['aflatoxin', 'aflatoxin dairy', 'animal', 'animal health', 'antimicrobial', 'antimicrobial resistance', 'app', 'asili', 'asili fertilizer', 'bean']\n",
                        "  Final feature count: 241 (base: 41, tfidf: 200)\n",
                        "  Training model... AUC=0.9566, LogLoss=0.0775\n",
                        "\n",
                        "================================================================================\n",
                        "TF-IDF Configuration Comparison (NO SVD, WITH ENGINEERED FEATURES):\n",
                        " max_features  test_auc  test_logloss  n_tfidf_features\n",
                        "          100  0.958092      0.077099               100\n",
                        "           50  0.958880      0.077215                50\n",
                        "          150  0.957048      0.077261               150\n",
                        "           30  0.959020      0.077267                30\n",
                        "           75  0.957939      0.077305                75\n",
                        "          200  0.956632      0.077482               200\n",
                        "================================================================================\n",
                        "\n",
                        "✓ Selected Configuration:\n",
                        "  TF-IDF max_features: 100\n",
                        "  Actual TF-IDF features created: 100\n",
                        "  Test AUC: 0.9581\n",
                        "  Test Log Loss: 0.0771\n",
                        "\n",
                        "============================== Final Test Results ==============================\n",
                        "\n",
                        "Classification Report:\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.97      1.00      0.99     11336\n",
                        "           1       0.62      0.04      0.08       348\n",
                        "\n",
                        "    accuracy                           0.97     11684\n",
                        "   macro avg       0.80      0.52      0.53     11684\n",
                        "weighted avg       0.96      0.97      0.96     11684\n",
                        "\n",
                        "Confusion Matrix:\n",
                        "[[11327     9]\n",
                        " [  333    15]]\n",
                        "\n",
                        "Test AUC: 0.9581\n",
                        "Test Log Loss: 0.0771\n",
                        "\n",
                        "Top 15 most important ENGINEERED features:\n",
                        "  - health_pct: 0.005987\n",
                        "  - num_domains_covered: 0.005405\n",
                        "  - livestock_pct: 0.005273\n",
                        "  - avg_topics_per_domain: 0.005010\n",
                        "  - business_pct: 0.004682\n",
                        "  - is_specialist: 0.004286\n",
                        "  - business_count: 0.004175\n",
                        "  - feed_pct: 0.004104\n",
                        "  - livestock_count: 0.004103\n",
                        "  - topic_count: 0.003983\n",
                        "  - max_domain_count: 0.003616\n",
                        "  - has_livestock_and_health: 0.003225\n",
                        "  - health_count: 0.003194\n",
                        "  - topic_diversity: 0.003137\n",
                        "  - has_business: 0.003091\n",
                        "\n",
                        "Top 15 most important TF-IDF features:\n",
                        "  - dairy: 0.010312\n",
                        "  - health: 0.010204\n",
                        "  - management: 0.008096\n",
                        "  - poultry: 0.007299\n",
                        "  - animal: 0.007201\n",
                        "  - dairy farm: 0.006391\n",
                        "  - tyari: 0.005635\n",
                        "  - health management: 0.005406\n",
                        "  - poultry health: 0.004757\n",
                        "  - deworming: 0.004517\n",
                        "  - fee: 0.004494\n",
                        "  - antimicrobial resistance: 0.004369\n",
                        "  - herd: 0.004346\n",
                        "  - mineral: 0.004263\n",
                        "  - supplementation: 0.004210\n",
                        "\n",
                        "Generating predicted probabilities on full dataset for chaining...\n",
                        "  Added 'adopted_within_90_days' predictions to feature set\n",
                        "  Prediction stats: min=0.0046, max=0.5479, mean=0.0309\n",
                        "\n",
                        "====================================================================== Training for 120 Days ======================================================================\n",
                        "\n",
                        "--- TF-IDF max_features=30 (NO SVD compression) ---\n",
                        "  TF-IDF shape: (46734, 30)\n",
                        "  Sparsity: 88.73%\n",
                        "  Top features: ['app', 'benefit', 'biodeal', 'chicken', 'cow', 'dairy', 'disease', 'farm', 'fee', 'feed']\n",
                        "  Final feature count: 72 (base: 42, tfidf: 30)\n",
                        "  Training model... AUC=0.9482, LogLoss=0.1045\n",
                        "\n",
                        "--- TF-IDF max_features=50 (NO SVD compression) ---\n",
                        "  TF-IDF shape: (46734, 50)\n",
                        "  Sparsity: 91.57%\n",
                        "  Top features: ['animal', 'app', 'benefit', 'benefit ndume', 'biodeal', 'biosecurity', 'biosecurity poultry', 'breed', 'calf', 'chicken']\n",
                        "  Final feature count: 92 (base: 42, tfidf: 50)\n",
                        "  Training model... AUC=0.9480, LogLoss=0.1044\n",
                        "\n",
                        "--- TF-IDF max_features=75 (NO SVD compression) ---\n",
                        "  TF-IDF shape: (46734, 75)\n",
                        "  Sparsity: 93.37%\n",
                        "  Top features: ['aflatoxin', 'animal', 'app', 'bean', 'benefit', 'benefit ndume', 'biodeal', 'biosecurity', 'biosecurity poultry', 'breed']\n",
                        "  Final feature count: 117 (base: 42, tfidf: 75)\n",
                        "  Training model... AUC=0.9479, LogLoss=0.1044\n",
                        "\n",
                        "--- TF-IDF max_features=100 (NO SVD compression) ---\n",
                        "  TF-IDF shape: (46734, 100)\n",
                        "  Sparsity: 94.37%\n",
                        "  Top features: ['aflatoxin', 'aflatoxin dairy', 'animal', 'antimicrobial', 'antimicrobial resistance', 'app', 'bean', 'benefit', 'benefit ndume', 'biodeal']\n",
                        "  Final feature count: 142 (base: 42, tfidf: 100)\n",
                        "  Training model... AUC=0.9476, LogLoss=0.1042\n",
                        "\n",
                        "--- TF-IDF max_features=150 (NO SVD compression) ---\n",
                        "  TF-IDF shape: (46734, 150)\n",
                        "  Sparsity: 95.56%\n",
                        "  Top features: ['aflatoxin', 'aflatoxin dairy', 'animal', 'antimicrobial', 'antimicrobial resistance', 'app', 'asili', 'asili fertilizer', 'bean', 'benefit']\n",
                        "  Final feature count: 192 (base: 42, tfidf: 150)\n",
                        "  Training model... AUC=0.9469, LogLoss=0.1044\n",
                        "\n",
                        "--- TF-IDF max_features=200 (NO SVD compression) ---\n",
                        "  TF-IDF shape: (46734, 200)\n",
                        "  Sparsity: 96.35%\n",
                        "  Top features: ['aflatoxin', 'aflatoxin dairy', 'animal', 'animal health', 'antimicrobial', 'antimicrobial resistance', 'app', 'asili', 'asili fertilizer', 'bean']\n",
                        "  Final feature count: 242 (base: 42, tfidf: 200)\n",
                        "  Training model... AUC=0.9466, LogLoss=0.1043\n",
                        "\n",
                        "================================================================================\n",
                        "TF-IDF Configuration Comparison (NO SVD, WITH ENGINEERED FEATURES):\n",
                        " max_features  test_auc  test_logloss  n_tfidf_features\n",
                        "          100  0.947599      0.104165               100\n",
                        "          200  0.946574      0.104349               200\n",
                        "          150  0.946892      0.104388               150\n",
                        "           50  0.947981      0.104437                50\n",
                        "           75  0.947892      0.104439                75\n",
                        "           30  0.948174      0.104496                30\n",
                        "================================================================================\n",
                        "\n",
                        "✓ Selected Configuration:\n",
                        "  TF-IDF max_features: 100\n",
                        "  Actual TF-IDF features created: 100\n",
                        "  Test AUC: 0.9476\n",
                        "  Test Log Loss: 0.1042\n",
                        "\n",
                        "============================== Final Test Results ==============================\n",
                        "\n",
                        "Classification Report:\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.96      1.00      0.98     11206\n",
                        "           1       0.55      0.09      0.15       478\n",
                        "\n",
                        "    accuracy                           0.96     11684\n",
                        "   macro avg       0.75      0.54      0.57     11684\n",
                        "weighted avg       0.95      0.96      0.95     11684\n",
                        "\n",
                        "Confusion Matrix:\n",
                        "[[11171    35]\n",
                        " [  436    42]]\n",
                        "\n",
                        "Test AUC: 0.9476\n",
                        "Test Log Loss: 0.1042\n",
                        "\n",
                        "Top 15 most important ENGINEERED features:\n",
                        "  - health_pct: 0.006476\n",
                        "  - topic_diversity: 0.005959\n",
                        "  - topic_count: 0.005559\n",
                        "  - livestock_count: 0.004704\n",
                        "  - avg_topics_per_domain: 0.004685\n",
                        "  - max_domain_count: 0.004497\n",
                        "  - num_domains_covered: 0.004451\n",
                        "  - health_count: 0.003667\n",
                        "  - livestock_pct: 0.003495\n",
                        "  - business_count: 0.003430\n",
                        "  - has_livestock_and_health: 0.003357\n",
                        "  - business_pct: 0.003111\n",
                        "  - is_specialist: 0.002748\n",
                        "  - feed_pct: 0.002513\n",
                        "  - crop_pct: 0.002313\n",
                        "\n",
                        "Top 15 most important TF-IDF features:\n",
                        "  - health: 0.006759\n",
                        "  - management: 0.005780\n",
                        "  - health management: 0.004833\n",
                        "  - poultry: 0.004737\n",
                        "  - dairy: 0.004514\n",
                        "  - dairy farm: 0.004506\n",
                        "  - herd: 0.004420\n",
                        "  - practice: 0.003558\n",
                        "  - animal: 0.003307\n",
                        "  - pest: 0.002842\n",
                        "  - app: 0.002784\n",
                        "  - ndume app: 0.002770\n",
                        "  - pest disease: 0.002723\n",
                        "  - tyari: 0.002664\n",
                        "  - ndume: 0.002645\n",
                        "\n",
                        "Generating predicted probabilities on full dataset for chaining...\n",
                        "  Added 'adopted_within_120_days' predictions to feature set\n",
                        "  Prediction stats: min=0.0068, max=0.5681, mean=0.0420\n",
                        "\n",
                        "================================================================================\n",
                        "Training Complete! Stored:\n",
                        "  models: ['7 Days', '90 Days', '120 Days']\n",
                        "  tfidf_vectorizers: ['7 Days', '90 Days', '120 Days']\n",
                        "  best_configs: {'7 Days': {'max_features': 100}, '90 Days': {'max_features': 100}, '120 Days': {'max_features': 100}}\n",
                        "  chained_features: ['adopted_within_07_days', 'adopted_within_90_days', 'adopted_within_120_days']\n",
                        "================================================================================\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.calibration import CalibratedClassifierCV\n",
                "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, log_loss\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import nltk\n",
                "from nltk.stem import WordNetLemmatizer\n",
                "\n",
                "# Download required NLTK data (run once)\n",
                "try:\n",
                "    nltk.data.find('corpora/wordnet')\n",
                "except LookupError:\n",
                "    nltk.download('wordnet')\n",
                "    nltk.download('omw-1.4')\n",
                "\n",
                "# Initialize lemmatizer\n",
                "lemmatizer = WordNetLemmatizer()\n",
                "\n",
                "# --- TF-IDF Configuration (NO SVD!) ---\n",
                "tfidf_max_features_options = [30, 50, 75, 100, 150, 200]\n",
                "\n",
                "# Targets\n",
                "target_mapping = {\n",
                "    '7 Days': 'adopted_within_07_days',\n",
                "    '90 Days': 'adopted_within_90_days',\n",
                "    '120 Days': 'adopted_within_120_days'\n",
                "}\n",
                "\n",
                "models = {}\n",
                "tfidf_vectorizers = {}\n",
                "best_configs = {}\n",
                "chained_features = []\n",
                "\n",
                "# --- Custom stopwords for agricultural domain ---\n",
                "custom_stopwords = list(set(ENGLISH_STOP_WORDS).union({\n",
                "    'how', 'to', 'from', 'with', 'your', 'for', 'the', 'and', 'in', 'of', 'a', 'an',\n",
                "    'day', 'old', 'care', 'using', 'about', 'on', 'at', 'by', 'after', 'before',\n",
                "    'week', 'weeks', 'maturity', 'products', 'product', 'use', 'uses', 'used',\n",
                "    'new', 'best', 'good', 'better', 'right', 'proper', 'important', 'importance'\n",
                "}))\n",
                "\n",
                "# --- Step 1: Convert binary topic features to cleaned and lemmatized text ---\n",
                "print(\"Converting topic features to text with preprocessing and lemmatization...\")\n",
                "\n",
                "def lemmatize_text(text):\n",
                "    \"\"\"Lemmatize text to normalize word forms\"\"\"\n",
                "    words = text.split()\n",
                "    lemmatized = []\n",
                "    \n",
                "    for word in words:\n",
                "        lemma = lemmatizer.lemmatize(word, pos='n')\n",
                "        if lemma == word:\n",
                "            lemma = lemmatizer.lemmatize(word, pos='v')\n",
                "        lemmatized.append(lemma)\n",
                "    \n",
                "    return ' '.join(lemmatized)\n",
                "\n",
                "def topics_to_text(row):\n",
                "    \"\"\"Convert binary topic features to cleaned and lemmatized text\"\"\"\n",
                "    active_topics = [col.replace('topic_', '') for col in topic_columns if row[col] == 1]\n",
                "    \n",
                "    if not active_topics:\n",
                "        return 'no_topics'\n",
                "    \n",
                "    text = ' '.join(active_topics)\n",
                "    text = text.lower()\n",
                "    text = text.replace('(', '').replace(')', '')\n",
                "    text = text.replace('-', ' ')\n",
                "    text = text.replace('_', ' ')\n",
                "    text = lemmatize_text(text)\n",
                "    \n",
                "    return text\n",
                "\n",
                "df['topic_text'] = df[topic_columns].apply(topics_to_text, axis=1)\n",
                "\n",
                "print(f\"\\nSample topic texts (after cleaning and lemmatization):\")\n",
                "for i in range(min(5, len(df))):\n",
                "    text = df['topic_text'].iloc[i]\n",
                "    preview = text[:100] + '...' if len(text) > 100 else text\n",
                "    print(f\"  {i+1}. {preview}\")\n",
                "\n",
                "print(f\"\\nTopic text statistics:\")\n",
                "topic_lengths = df['topic_text'].str.split().str.len()\n",
                "print(f\"  Words per farmer: min={topic_lengths.min()}, max={topic_lengths.max()}, mean={topic_lengths.mean():.1f}\")\n",
                "print(f\"  Farmers with no topics: {(df['topic_text'] == 'no_topics').sum()}\")\n",
                "\n",
                "# --- Get non-topic features for base model ---\n",
                "base_features = [f for f in FEATURES if not f.startswith('topic_')]\n",
                "print(f\"\\nBase features (non-topic): {len(base_features)}\")\n",
                "print(f\"Topic features: {len(topic_columns)}\")\n",
                "\n",
                "# --- Step 2: Train models with different TF-IDF configurations (NO SVD) ---\n",
                "df_predictions = df.copy()\n",
                "\n",
                "for period, target in target_mapping.items():\n",
                "    print(f\"\\n{'='*70} Training for {period} {'='*70}\")\n",
                "\n",
                "    # Include previous PREDICTED probabilities as features\n",
                "    X_full = df_predictions[base_features + chained_features].copy()\n",
                "    y = df[target]\n",
                "\n",
                "    # Split train/test for evaluation\n",
                "    X_train_base, X_test_base, y_train, y_test = train_test_split(\n",
                "        X_full, y, test_size=0.2, random_state=42, stratify=y\n",
                "    )\n",
                "    \n",
                "    # Get topic text for train/test\n",
                "    train_topic_text = df.loc[X_train_base.index, 'topic_text']\n",
                "    test_topic_text = df.loc[X_test_base.index, 'topic_text']\n",
                "\n",
                "    # --- Evaluate different TF-IDF configurations (NO SVD COMPRESSION) ---\n",
                "    results = []\n",
                "    trained_models = []\n",
                "    \n",
                "    for max_features in tfidf_max_features_options:\n",
                "        print(f\"\\n--- TF-IDF max_features={max_features} (NO SVD compression) ---\")\n",
                "        \n",
                "        # Fit TF-IDF on training data\n",
                "        tfidf = TfidfVectorizer(\n",
                "            max_features=max_features,\n",
                "            ngram_range=(1, 2),\n",
                "            min_df=3,\n",
                "            max_df=0.85,\n",
                "            sublinear_tf=True,\n",
                "            stop_words=custom_stopwords,\n",
                "            lowercase=True,\n",
                "            token_pattern=r'\\b[a-z]{3,}\\b'\n",
                "        )\n",
                "        \n",
                "        X_train_tfidf = tfidf.fit_transform(train_topic_text)\n",
                "        X_test_tfidf = tfidf.transform(test_topic_text)\n",
                "        \n",
                "        print(f\"  TF-IDF shape: {X_train_tfidf.shape}\")\n",
                "        print(f\"  Sparsity: {(1 - X_train_tfidf.nnz / (X_train_tfidf.shape[0] * X_train_tfidf.shape[1])):.2%}\")\n",
                "        print(f\"  Top features: {list(tfidf.get_feature_names_out())[:10]}\")\n",
                "        \n",
                "        # Convert sparse matrix to dense\n",
                "        X_train_tfidf_dense = X_train_tfidf.toarray()\n",
                "        X_test_tfidf_dense = X_test_tfidf.toarray()\n",
                "        \n",
                "        # Combine base features + TF-IDF features\n",
                "        X_train_final = np.hstack([X_train_base.values, X_train_tfidf_dense])\n",
                "        X_test_final = np.hstack([X_test_base.values, X_test_tfidf_dense])\n",
                "        \n",
                "        print(f\"  Final feature count: {X_train_final.shape[1]} (base: {X_train_base.shape[1]}, tfidf: {X_train_tfidf_dense.shape[1]})\")\n",
                "\n",
                "        # Train calibrated RandomForest\n",
                "        rf = RandomForestClassifier(\n",
                "            n_estimators=800,\n",
                "            max_features=\"sqrt\",\n",
                "            min_samples_leaf=3,\n",
                "            class_weight=\"balanced_subsample\",\n",
                "            random_state=42,\n",
                "            n_jobs=-1\n",
                "        )\n",
                "\n",
                "        calibrated_rf = CalibratedClassifierCV(\n",
                "            estimator=rf,\n",
                "            method=\"sigmoid\",\n",
                "            cv=3\n",
                "        )\n",
                "        \n",
                "        print(f\"  Training model...\", end=' ')\n",
                "        calibrated_rf.fit(X_train_final, y_train)\n",
                "\n",
                "        # Evaluate\n",
                "        y_pred_proba = calibrated_rf.predict_proba(X_test_final)[:, 1]\n",
                "        test_auc = roc_auc_score(y_test, y_pred_proba)\n",
                "        test_logloss = log_loss(y_test, y_pred_proba)\n",
                "        \n",
                "        print(f\"AUC={test_auc:.4f}, LogLoss={test_logloss:.4f}\")\n",
                "        \n",
                "        results.append({\n",
                "            'max_features': max_features,\n",
                "            'test_auc': test_auc,\n",
                "            'test_logloss': test_logloss,\n",
                "            'n_tfidf_features': X_train_tfidf_dense.shape[1]\n",
                "        })\n",
                "        \n",
                "        trained_models.append({\n",
                "            'max_features': max_features,\n",
                "            'model': calibrated_rf,\n",
                "            'tfidf': tfidf\n",
                "        })\n",
                "    \n",
                "    # --- Display results and select best based on log loss ---\n",
                "    results_df = pd.DataFrame(results)\n",
                "    print(\"\\n\" + \"=\"*80)\n",
                "    print(\"TF-IDF Configuration Comparison (NO SVD):\")\n",
                "    print(results_df.sort_values('test_logloss').to_string(index=False))\n",
                "    print(\"=\"*80)\n",
                "    \n",
                "    # Select best based on log loss\n",
                "    best_idx = results_df['test_logloss'].idxmin()\n",
                "    best_result = results_df.loc[best_idx]\n",
                "    \n",
                "    print(f\"\\n✓ Selected Configuration:\")\n",
                "    print(f\"  TF-IDF max_features: {int(best_result['max_features'])}\")\n",
                "    print(f\"  Actual TF-IDF features created: {int(best_result['n_tfidf_features'])}\")\n",
                "    print(f\"  Test AUC: {best_result['test_auc']:.4f}\")\n",
                "    print(f\"  Test Log Loss: {best_result['test_logloss']:.4f}\")\n",
                "\n",
                "    # Store the best model and transformers\n",
                "    best_model_info = trained_models[best_idx]\n",
                "    models[period] = best_model_info['model']\n",
                "    tfidf_vectorizers[period] = best_model_info['tfidf']\n",
                "    best_configs[period] = {\n",
                "        'max_features': int(best_result['max_features'])\n",
                "    }\n",
                "    \n",
                "    # --- Final evaluation with best model ---\n",
                "    tfidf = best_model_info['tfidf']\n",
                "    \n",
                "    # Recreate the TF-IDF features for the best model\n",
                "    X_train_tfidf_best = tfidf.transform(train_topic_text).toarray()\n",
                "    X_test_tfidf_best = tfidf.transform(test_topic_text).toarray()\n",
                "    \n",
                "    # Recreate final features\n",
                "    X_train_final_best = np.hstack([X_train_base.values, X_train_tfidf_best])\n",
                "    X_test_final_best = np.hstack([X_test_base.values, X_test_tfidf_best])\n",
                "    \n",
                "    print(f\"\\n{'='*30} Final Test Results {'='*30}\")\n",
                "    y_pred = best_model_info['model'].predict(X_test_final_best)\n",
                "    y_pred_proba = best_model_info['model'].predict_proba(X_test_final_best)[:, 1]\n",
                "\n",
                "    print(\"\\nClassification Report:\")\n",
                "    print(classification_report(y_test, y_pred))\n",
                "    print(\"Confusion Matrix:\")\n",
                "    print(confusion_matrix(y_test, y_pred))\n",
                "\n",
                "    print(f\"\\nTest AUC: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
                "    print(f\"Test Log Loss: {log_loss(y_test, y_pred_proba):.4f}\")\n",
                "    \n",
                "    # Show top TF-IDF features by feature importance (COMPLETELY FIXED)\n",
                "    print(f\"\\nTop 20 most important TF-IDF features (by Random Forest importance):\")\n",
                "    \n",
                "    # Use the recreated arrays to get correct dimensions\n",
                "    actual_n_base = X_train_base.shape[1]\n",
                "    actual_n_tfidf = X_train_tfidf_best.shape[1]\n",
                "    \n",
                "    # Get feature importances from the base estimator\n",
                "    feature_importances = best_model_info['model'].calibrated_classifiers_[0].estimator.feature_importances_\n",
                "    \n",
                "    # Extract just the TF-IDF portion using actual array dimensions\n",
                "    tfidf_importances = feature_importances[actual_n_base:actual_n_base + actual_n_tfidf]\n",
                "    tfidf_feature_names = tfidf.get_feature_names_out()\n",
                "    \n",
                "    # Verify lengths match\n",
                "    if len(tfidf_importances) != len(tfidf_feature_names):\n",
                "        print(f\"  WARNING: Mismatch - {len(tfidf_importances)} importances vs {len(tfidf_feature_names)} names\")\n",
                "        print(f\"  Skipping feature importance display.\")\n",
                "    else:\n",
                "        # Show top features\n",
                "        n_features_to_show = min(20, len(tfidf_feature_names))\n",
                "        top_indices = tfidf_importances.argsort()[-n_features_to_show:][::-1]\n",
                "        \n",
                "        for idx in top_indices:\n",
                "            print(f\"  - {tfidf_feature_names[idx]}: {tfidf_importances[idx]:.6f}\")\n",
                "\n",
                "    # --- Generate predictions on FULL dataset for next period ---\n",
                "    print(f\"\\nGenerating predicted probabilities on full dataset for chaining...\")\n",
                "    \n",
                "    full_topic_text = df['topic_text']\n",
                "    full_tfidf = tfidf.transform(full_topic_text).toarray()\n",
                "    \n",
                "    X_full_final = np.hstack([df_predictions[base_features + chained_features].values, full_tfidf])\n",
                "    \n",
                "    full_predictions = best_model_info['model'].predict_proba(X_full_final)[:, 1]\n",
                "    \n",
                "    df_predictions[target] = full_predictions\n",
                "    chained_features.append(target)\n",
                "    \n",
                "    print(f\"  Added '{target}' predictions to feature set\")\n",
                "    print(f\"  Prediction stats: min={full_predictions.min():.4f}, max={full_predictions.max():.4f}, mean={full_predictions.mean():.4f}\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"Training Complete! Stored:\")\n",
                "print(f\"  models: {list(models.keys())}\")\n",
                "print(f\"  tfidf_vectorizers: {list(tfidf_vectorizers.keys())}\")\n",
                "print(f\"  best_configs: {best_configs}\")\n",
                "print(f\"  chained_features: {chained_features}\")\n",
                "print(\"=\"*80)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "id": "23bce03b",
            "metadata": {},
            "outputs": [],
            "source": [
                "# from xgboost import XGBClassifier\n",
                "# from sklearn.model_selection import train_test_split\n",
                "# from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, log_loss\n",
                "\n",
                "# target_mapping = {\n",
                "#     \"7 Days\": \"adopted_within_07_days\",\n",
                "#     \"90 Days\": \"adopted_within_90_days\",\n",
                "#     \"120 Days\": \"adopted_within_120_days\"\n",
                "# }\n",
                "\n",
                "# models = {}\n",
                "\n",
                "# # For each horizon\n",
                "# for period, target in target_mapping.items():\n",
                "#     print(f\"\\n{'='*20} Training XGBoost for {period} {'='*20}\")\n",
                "\n",
                "#     X = df[FEATURES].copy()\n",
                "#     y = df[target]\n",
                "\n",
                "#     # Add predictions from previous horizons as features\n",
                "#     for prev_period, prev_target in list(target_mapping.items()):\n",
                "#         if prev_period == period:\n",
                "#             break\n",
                "#         X[f\"pred_{prev_target}\"] = df[prev_target]  # Using actual labels for training\n",
                "\n",
                "#     X_train, X_test, y_train, y_test = train_test_split(\n",
                "#         X, y, test_size=0.2, stratify=y, random_state=42\n",
                "#     )\n",
                "\n",
                "#     xgb_model = XGBClassifier(\n",
                "#         n_estimators=1000,\n",
                "#         learning_rate=0.03,\n",
                "#         max_depth=6,\n",
                "#         subsample=0.8,\n",
                "#         colsample_bytree=0.8,\n",
                "#         eval_metric=\"logloss\",\n",
                "#         use_label_encoder=False,\n",
                "#         random_state=42,\n",
                "#         n_jobs=-1\n",
                "#     )\n",
                "\n",
                "#     xgb_model.fit(\n",
                "#         X_train, y_train,\n",
                "#         eval_set=[(X_test, y_test)],\n",
                "#         early_stopping_rounds=50,\n",
                "#         verbose=False\n",
                "#     )\n",
                "\n",
                "#     models[period] = xgb_model\n",
                "\n",
                "#     y_pred = xgb_model.predict(X_test)\n",
                "#     y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
                "\n",
                "#     print(\"\\nClassification Report:\")\n",
                "#     print(classification_report(y_test, y_pred))\n",
                "#     print(\"Confusion Matrix:\")\n",
                "#     print(confusion_matrix(y_test, y_pred))\n",
                "#     print(f\"AUC Score: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
                "#     print(f\"Log Loss: {log_loss(y_test, y_pred_proba):.4f}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ec2f3cba",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Creating engineered features for test data...\n",
                        "Engineered features created for test data!\n",
                        "\n",
                        "Generating chained predictions with TF-IDF + Engineered Features...\n",
                        "\n",
                        "Predicting for 7 Days...\n",
                        "  Using TF-IDF (max_features=100) + 26 engineered features\n",
                        "  Predicted probabilities: min=0.0022, max=0.2060, mean=0.0047\n",
                        "\n",
                        "Predicting for 90 Days...\n",
                        "  Using TF-IDF (max_features=100) + 26 engineered features\n",
                        "  Predicted probabilities: min=0.0046, max=0.2700, mean=0.0081\n",
                        "\n",
                        "Predicting for 120 Days...\n",
                        "  Using TF-IDF (max_features=100) + 26 engineered features\n",
                        "  Predicted probabilities: min=0.0068, max=0.3273, mean=0.0098\n",
                        "\n",
                        "Done! Submission saved to submission_tfidf_engineered.csv\n",
                        "          ID  Target_07_AUC  Target_07_LogLoss  Target_90_AUC  \\\n",
                        "0  ID_LEG1GM       0.002818           0.002818       0.005615   \n",
                        "1  ID_1UKOKW       0.002413           0.002413       0.005454   \n",
                        "2  ID_U5H2YK       0.006509           0.006509       0.008666   \n",
                        "3  ID_55957A       0.005612           0.005612       0.007668   \n",
                        "4  ID_N1AC0A       0.002396           0.002396       0.005226   \n",
                        "\n",
                        "   Target_90_LogLoss  Target_120_AUC  Target_120_LogLoss  \n",
                        "0           0.005615        0.008089            0.008089  \n",
                        "1           0.005454        0.007626            0.007626  \n",
                        "2           0.008666        0.009741            0.009741  \n",
                        "3           0.007668        0.008676            0.008676  \n",
                        "4           0.005226        0.007729            0.007729  \n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import ast\n",
                "import numpy as np\n",
                "import nltk\n",
                "from nltk.stem import WordNetLemmatizer\n",
                "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
                "\n",
                "# Initialize lemmatizer\n",
                "lemmatizer = WordNetLemmatizer()\n",
                "\n",
                "# -------------------------\n",
                "# Functions (MUST MATCH TRAINING)\n",
                "# -------------------------\n",
                "def clean_and_flat_topics(topic_str):\n",
                "    if not isinstance(topic_str, str) or pd.isna(topic_str):\n",
                "        return []\n",
                "    \n",
                "    try:\n",
                "        parsed = ast.literal_eval(topic_str)\n",
                "    except (ValueError, SyntaxError):\n",
                "        return []\n",
                "\n",
                "    flat_topics = []\n",
                "    def flatten(item):\n",
                "        if isinstance(item, list):\n",
                "            for sub in item:\n",
                "                flatten(sub)\n",
                "        elif isinstance(item, str):\n",
                "            flat_topics.append(item)\n",
                "    flatten(parsed)\n",
                "    cleaned = sorted(list(set([t.lower().strip() for t in flat_topics if t])))\n",
                "    return cleaned\n",
                "\n",
                "def lemmatize_text(text):\n",
                "    \"\"\"Lemmatize text to normalize word forms\"\"\"\n",
                "    words = text.split()\n",
                "    lemmatized = []\n",
                "    \n",
                "    for word in words:\n",
                "        lemma = lemmatizer.lemmatize(word, pos='n')\n",
                "        if lemma == word:\n",
                "            lemma = lemmatizer.lemmatize(word, pos='v')\n",
                "        lemmatized.append(lemma)\n",
                "    \n",
                "    return ' '.join(lemmatized)\n",
                "\n",
                "def topics_to_text(row):\n",
                "    \"\"\"Convert binary topic features to cleaned and lemmatized text\"\"\"\n",
                "    active_topics = [col.replace('topic_', '') for col in topic_columns if row[col] == 1]\n",
                "    \n",
                "    if not active_topics:\n",
                "        return 'no_topics'\n",
                "    \n",
                "    text = ' '.join(active_topics)\n",
                "    text = text.lower()\n",
                "    text = text.replace('(', '').replace(')', '')\n",
                "    text = text.replace('-', ' ')\n",
                "    text = text.replace('_', ' ')\n",
                "    text = lemmatize_text(text)\n",
                "    \n",
                "    return text\n",
                "\n",
                "# -------------------------\n",
                "# Load test data\n",
                "# -------------------------\n",
                "test_df = pd.read_csv(\"Original Data/Test.csv\")\n",
                "\n",
                "# -------------------------\n",
                "# Preprocess topics\n",
                "# -------------------------\n",
                "test_df['clean_topics'] = test_df['topics_list'].apply(clean_and_flat_topics)\n",
                "\n",
                "topics_encoded = mlb.transform(test_df['clean_topics'])\n",
                "topic_columns_list = [f'topic_{t}' for t in mlb.classes_]\n",
                "topics_df = pd.DataFrame(topics_encoded, columns=topic_columns_list, index=test_df.index)\n",
                "test_df = pd.concat([test_df, topics_df], axis=1)\n",
                "\n",
                "test_df['topic_text'] = test_df[topic_columns].apply(topics_to_text, axis=1)\n",
                "\n",
                "print(f\"\\nTest data topic text samples (lemmatized):\")\n",
                "for i in range(min(3, len(test_df))):\n",
                "    text = test_df['topic_text'].iloc[i]\n",
                "    preview = text[:100] + '...' if len(text) > 100 else text\n",
                "    print(f\"  {i+1}. {preview}\")\n",
                "\n",
                "# -------------------------\n",
                "# Date features\n",
                "# -------------------------\n",
                "if 'training_day' in test_df.columns:\n",
                "    test_df['training_day'] = pd.to_datetime(test_df['training_day'], dayfirst=True)\n",
                "    test_df['training_year'] = test_df['training_day'].dt.year\n",
                "    test_df['training_month'] = test_df['training_day'].dt.month\n",
                "    test_df['training_day_number'] = test_df['training_day'].dt.day\n",
                "    test_df['training_dayofweek'] = test_df['training_day'].dt.dayofweek\n",
                "\n",
                "# -------------------------\n",
                "# Encode categorical features safely\n",
                "# -------------------------\n",
                "base_features = [f for f in FEATURES if not f.startswith('topic_')]\n",
                "\n",
                "for col in base_features:\n",
                "    if col in test_df.columns:\n",
                "        if col in label_encoders:\n",
                "            le = label_encoders[col]\n",
                "            test_df[col] = test_df[col].astype(str).fillna(\"NA\")\n",
                "            test_df[col] = test_df[col].map(lambda s: s if s in le.classes_ else le.classes_[0])\n",
                "            test_df[col] = le.transform(test_df[col])\n",
                "        else:\n",
                "            if test_df[col].dtype == \"object\":\n",
                "                test_df[col] = 0\n",
                "\n",
                "for feat in base_features:\n",
                "    if feat not in test_df.columns:\n",
                "        test_df[feat] = 0\n",
                "\n",
                "X_test_base = test_df[base_features].copy()\n",
                "\n",
                "# -------------------------\n",
                "# Prepare submission\n",
                "# -------------------------\n",
                "submission = pd.DataFrame()\n",
                "submission[\"ID\"] = test_df[\"ID\"] if \"ID\" in test_df.columns else range(1, len(test_df) + 1)\n",
                "\n",
                "submission_mapping = {\n",
                "    \"7 Days\": [\"Target_07_AUC\", \"Target_07_LogLoss\"],\n",
                "    \"90 Days\": [\"Target_90_AUC\", \"Target_90_LogLoss\"],\n",
                "    \"120 Days\": [\"Target_120_AUC\", \"Target_120_LogLoss\"]\n",
                "}\n",
                "\n",
                "# -------------------------\n",
                "# Generate chained predictions\n",
                "# -------------------------\n",
                "print(\"\\nGenerating chained predictions with TF-IDF (NO SVD, using predicted probabilities)...\")\n",
                "\n",
                "for period, target in [\n",
                "    (\"7 Days\", \"adopted_within_07_days\"),\n",
                "    (\"90 Days\", \"adopted_within_90_days\"),\n",
                "    (\"120 Days\", \"adopted_within_120_days\")\n",
                "]:\n",
                "    print(f\"\\nPredicting for {period}...\")\n",
                "    \n",
                "    model = models[period]\n",
                "    tfidf = tfidf_vectorizers[period]\n",
                "    config = best_configs[period]\n",
                "    \n",
                "    print(f\"  Using TF-IDF (max_features={config['max_features']}, NO SVD compression)\")\n",
                "    \n",
                "    # Transform test data\n",
                "    X_test_tfidf = tfidf.transform(test_df['topic_text']).toarray()\n",
                "    \n",
                "    # Combine base features + TF-IDF features\n",
                "    X_test_final = np.hstack([X_test_base.values, X_test_tfidf])\n",
                "\n",
                "    # Predict probabilities\n",
                "    probs = model.predict_proba(X_test_final)[:, 1]\n",
                "    \n",
                "    print(f\"  Predicted probabilities: min={probs.min():.4f}, max={probs.max():.4f}, mean={probs.mean():.4f}\")\n",
                "\n",
                "    # Fill submission columns\n",
                "    for col in submission_mapping[period]:\n",
                "        submission[col] = probs\n",
                "\n",
                "    # Append PREDICTED probability as feature for next horizon\n",
                "    X_test_base[target] = probs\n",
                "\n",
                "# -------------------------\n",
                "# Save submission\n",
                "# -------------------------\n",
                "submission.to_csv(\"submission_tfidf_no_svd.csv\", index=False)\n",
                "print(\"\\nDone! Submission saved to submission_tfidf_no_svd.csv\")\n",
                "print(submission.head())"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python (DigiCow)",
            "language": "python",
            "name": "digicow-venv"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
